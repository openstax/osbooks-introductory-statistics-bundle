<document xmlns="http://cnx.rice.edu/cnxml" class="introduction">
  <title>Introduction</title>
  <metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m54530</md:content-id>
  <md:title>Introduction</md:title>
  <md:abstract/>
  <md:uuid>471a7480-081e-4429-baa2-5483c54e067b</md:uuid>
</metadata>

<content>
  <figure id="fs-idm16905488" class="splash"><media id="fs-idm70194688" alt="This is a photo of change a set of keys in a pile. There appear to be five pennies, three quarters, four dimes, and two nickels. The key ring has a bronze whale on it and holds eleven keys.">
<image mime-type="image/jpg" src="../../media/CNX_Stats_C07_CO.jpg"/>
</media>

<caption>If you want to figure out the distribution of the change people carry in their pockets, using the Central Limit Theorem and assuming your sample is large enough, you will find that the  distribution is the normal probability density function. (credit: John Lodder)</caption></figure><para id="eip-8888">Why are we so concerned with means? Two reasons are: they give us a middle ground for comparison, and they are easy to calculate. In this chapter, you will study means and the <emphasis>Central Limit Theorem</emphasis>.</para><para id="element-164">The <term id="term-00001">Central Limit Theorem</term> is one of the most powerful and useful ideas in all of statistics. The Central Limit Theorem is a theorem which means that it is NOT a theory or just somebody's idea of the way things work. As a theorem it ranks with the Pythagorean Theorem, or the theorem that tells us that the sum of the angles of a triangle must add to 180. These are facts of the ways of the world rigorously demonstrated with mathematical precision and logic. As we will see this powerful theorem will determine just what we can, and cannot say, in inferential statistics. The Central Limit Theorem is concerned with drawing finite samples of size <emphasis effect="italics">n</emphasis> from a population with a known mean, <emphasis effect="italics">μ</emphasis>, and a known standard deviation, <emphasis effect="italics">σ</emphasis>. The conclusion is that if we collect samples of size <emphasis effect="italics">n</emphasis> with a "large enough <emphasis effect="italics">n</emphasis>," calculate each sample's mean, and create a histogram (distribution) of those means, then the resulting distribution will tend to have an approximate normal distribution. </para><para id="element-328"><emphasis>The astounding result is that it does not matter what the distribution of the original population is, or whether you even need to know it. The important fact is that the distribution of sample means tend to follow the normal distribution.</emphasis></para><para id="element-17">The size of the sample, <emphasis effect="italics">n</emphasis>, that is required in order to be "large enough" depends on the original population from which the samples are drawn (the sample size should be at least 30 or the data should come from a normal distribution). If the original population is far from normal, then more observations are needed for the sample means. <emphasis>Sampling is done randomly and with replacement in the theoretical model.</emphasis></para> </content>

  <glossary>
<definition id="fs-idm28209360">
<term>Sampling Distribution</term>
<meaning id="fs-idm33714048">Given simple random samples of size <emphasis effect="italics">n</emphasis> from a given population with a measured characteristic such as mean, proportion, or standard deviation for each sample, the probability distribution of all the measured characteristics is called a sampling distribution.</meaning>
</definition>
</glossary>
</document>